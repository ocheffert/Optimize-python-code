{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to optimize scientific python code\r\n",
    "\r\n",
    "This notebook gives tips to optimize pure python and Numpy codes. This is mainly for scientific codes so strings or dictionnaries will not be covered in this document but infos about those topics can be found in the references and the end of the notebook.\r\n",
    "\r\n",
    "**Table of content**\r\n",
    "1. [Finding the bottlenecks by profiling](#profile)\r\n",
    "2. [Pure python code](#pure)\r\n",
    "3. [Numpy code](#numpy)\r\n",
    "4. [References](#ref)\r\n",
    "5. [Further readings](#further)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the bottlenecks by profiling <a name=\"profile\"></a>\r\n",
    "\r\n",
    "Firstly, note that optimizing the whole code is not a good idea since it requires a lot of time even where the gain is not worth it. Indeed, you just need to optimize the slow parts of your code. In this situation, you can optimize those parts or write them in compiled code (cython, C, ...) but this notebook will focus on the first option because in some case optimizing the python code can achieve a sufficient speed up without rewriting it in a compiled language.\r\n",
    "\r\n",
    "\r\n",
    "In this notebook, we will use the profiler cProfile that is not the most heavy in terms of overheads but also the line by line profile line_profiler.\r\n",
    "\r\n",
    "In [this towards data science blog](https://towardsdatascience.com/how-to-profile-your-code-in-python-e70c834fad89), a decorator has been given to profile a function and find the bottlenecks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\r\n",
    "import pstats\r\n",
    "from functools import wraps\r\n",
    "\r\n",
    "\r\n",
    "def profile(output_file=None, sort_by='cumulative', lines_to_print=None, strip_dirs=False):\r\n",
    "    \"\"\"A time profiler decorator.\r\n",
    "    Inspired by and modified the profile decorator of Giampaolo Rodola:\r\n",
    "    http://code.activestate.com/recipes/577817-profile-decorator/\r\n",
    "    Args:\r\n",
    "        output_file: str or None. Default is None\r\n",
    "            Path of the output file. If only name of the file is given, it's\r\n",
    "            saved in the current directory.\r\n",
    "            If it's None, the name of the decorated function is used.\r\n",
    "        sort_by: str or SortKey enum or tuple/list of str/SortKey enum\r\n",
    "            Sorting criteria for the Stats object.\r\n",
    "            For a list of valid string and SortKey refer to:\r\n",
    "            https://docs.python.org/3/library/profile.html#pstats.Stats.sort_stats\r\n",
    "        lines_to_print: int or None\r\n",
    "            Number of lines to print. Default (None) is for all the lines.\r\n",
    "            This is useful in reducing the size of the printout, especially\r\n",
    "            that sorting by 'cumulative', the time consuming operations\r\n",
    "            are printed toward the top of the file.\r\n",
    "        strip_dirs: bool\r\n",
    "            Whether to remove the leading path info from file names.\r\n",
    "            This is also useful in reducing the size of the printout\r\n",
    "    Returns:\r\n",
    "        Profile of the decorated function\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def inner(func):\r\n",
    "        @wraps(func)\r\n",
    "        def wrapper(*args, **kwargs):\r\n",
    "            _output_file = output_file or func.__name__ + '.prof'\r\n",
    "            pr = cProfile.Profile()\r\n",
    "            pr.enable()\r\n",
    "            retval = func(*args, **kwargs)\r\n",
    "            pr.disable()\r\n",
    "            pr.dump_stats(_output_file)\r\n",
    "\r\n",
    "            with open(_output_file, 'w') as f:\r\n",
    "                ps = pstats.Stats(pr, stream=f)\r\n",
    "                if strip_dirs:\r\n",
    "                    ps.strip_dirs()\r\n",
    "                if isinstance(sort_by, (tuple, list)):\r\n",
    "                    ps.sort_stats(*sort_by)\r\n",
    "                else:\r\n",
    "                    ps.sort_stats(sort_by)\r\n",
    "                ps.print_stats(lines_to_print)\r\n",
    "            return retval\r\n",
    "\r\n",
    "        return wrapper\r\n",
    "\r\n",
    "    return inner\r\n",
    "\r\n",
    "\r\n",
    "@profile(sort_by='cumulative', lines_to_print=10, strip_dirs=True)\r\n",
    "def function(x):\r\n",
    "    res = []\r\n",
    "    double = lambda y: 2*y\r\n",
    "    for i in range(len(x)):\r\n",
    "        res.append(double(x[i]))\r\n",
    "\r\n",
    "List = [1]*10_000_000\r\n",
    "function(List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output file, we can find this:\r\n",
    "\r\n",
    "![cProfiler example](cProf.PNG)\r\n",
    "\r\n",
    "\r\n",
    "The profiler has given the execution time for each function call and we can see that on the total of 4.126 s the most of the operation come from the operations in `function` (probably the for loop), the calls to `append` and the calls to `double`, the lambda function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can also use a line by line profiler as `line_profiler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.156559 s\n",
      "File: <ipython-input-7-20893b078624>\n",
      "Function: function2 at line 8\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     8                                           @profile\n",
      "     9                                           def function2(x):\n",
      "    10         1         20.0     20.0      0.0      res = []\n",
      "    11         1         13.0     13.0      0.0      double = lambda y: 2*y\n",
      "    12    100001     510238.0      5.1     32.6      for i in range(len(x)):\n",
      "    13    100000    1055309.0     10.6     67.4          res.append(double(x[i]))\n",
      "    14         1          8.0      8.0      0.0      return 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from line_profiler import\r\n",
    "# from memory_profiler import profile   # for memory profiling\r\n",
    "import atexit\r\n",
    "\r\n",
    "profile = LineProfiler()\r\n",
    "atexit.register(profile.print_stats)\r\n",
    "\r\n",
    "\r\n",
    "@profile\r\n",
    "def function2(x):\r\n",
    "    res = []\r\n",
    "    double = lambda y: 2*y\r\n",
    "    for i in range(len(x)):\r\n",
    "        res.append(double(x[i]))\r\n",
    "    return 0\r\n",
    "\r\n",
    "\r\n",
    "List = [1]*100_000\r\n",
    "function2(List)\r\n",
    "profile.print_stats()   # in IPython atexit.register() does not work so I need to add it manually or create a decorator to dot it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to this line by line profiler we clrealy see at which line(s) the code is slowing down, here it's the line in the for loop. \r\n",
    "\r\n",
    "\r\n",
    "To sum, up we have two tools to profile our code and find the bottlenecks that have to be optimized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pure python code <a name=\"pure\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops\r\n",
    "\r\n",
    "For loops are costly in python... thus one can propose to use the `map` function to move the for loop into the C code and not python code anymore.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608 µs ± 74.9 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "284 ns ± 23.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "myList = [\"a\", \"B\", \"c\"]*1000\r\n",
    "\r\n",
    "def f1(l1):\r\n",
    "    res = []\r\n",
    "    for i in range(len(l1)):\r\n",
    "        res.append(l1[i].upper())\r\n",
    "    return res\r\n",
    "\r\n",
    "def f2(l2):\r\n",
    "    return map(str.upper, l2)\r\n",
    "\r\n",
    "\r\n",
    "%timeit f1(myList)\r\n",
    "%timeit f2(myList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so map is clrealy much faster than a for loop but is it always the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.43 µs ± 72.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "733 ns ± 106 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "1.57 µs ± 172 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "357 ns ± 7.57 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "314 ns ± 44.6 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import timeit\r\n",
    "\r\n",
    "\r\n",
    "xs = list(range(10))\r\n",
    "\r\n",
    "def f1(l1):\r\n",
    "    return list(map(lambda x: x*x, l1))\r\n",
    "\r\n",
    "def f2(l2):\r\n",
    "    return [x*x for x in l2]\r\n",
    "\r\n",
    "def f3(l3):\r\n",
    "    res = [0]*len(l3)\r\n",
    "    for i in range(len(l3)):\r\n",
    "        res[i] = l3[i]*l3[i]\r\n",
    "    return res\r\n",
    "\r\n",
    "def f4(l4):\r\n",
    "    return (x*x for x in l4)\r\n",
    "\r\n",
    "def f5(l5):\r\n",
    "    return map(lambda x: x*x, l5)\r\n",
    "\r\n",
    "\r\n",
    "%timeit f1(xs)\r\n",
    "%timeit f2(xs)\r\n",
    "%timeit f3(xs)\r\n",
    "%timeit f4(xs)\r\n",
    "%timeit f5(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops... in this case, `map` is clearly slower than a list comprehension (function `f2`) when we need to build a list...\r\n",
    "\r\n",
    "In fact, in python the function overheads are heavy and creating a lambda or a python function via `def` can slow down the map function.\r\n",
    "\r\n",
    "For the two lasts functions, this makes a generator that is clrealy much faster than a list and is lazy, so that each element is generated only when it's required (so no memory problems). And in this case, the map function becomes faster but the difference is not as high as we can expect for a Python VS C code performance comparison.\r\n",
    "\r\n",
    "As a general tip, try and timeit because a list comprehension can be faster than map especially if you map a python non built in function.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.2 µs ± 4.17 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "42.9 µs ± 2.5 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def f1(list):\r\n",
    "    newlist = []\r\n",
    "    append = newlist.append\r\n",
    "    doHash = int.__hash__\r\n",
    "    for element in list:\r\n",
    "        append(doHash(element))\r\n",
    "\r\n",
    "def f2(list):\r\n",
    "    newlist = []\r\n",
    "    for element in list:\r\n",
    "        newlist.append(int.__hash__(element))\r\n",
    "\r\n",
    "\r\n",
    "%timeit f1([2]*200)\r\n",
    "%timeit f2([2]*200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if we use `append` (which is not recommended for optimizations) we can observe a speed up with those simple changes.\r\n",
    "\r\n",
    "However, this makes the code a harder to read and maintain therefore you should be very familiar with your code when you use this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.3 µs ± 2.37 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "15.4 µs ± 381 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "18.7 µs ± 983 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\r\n",
    "    return x+1\r\n",
    "\r\n",
    "def g(x):\r\n",
    "    y = []\r\n",
    "    for i in range(len(x)):\r\n",
    "        y.append(f(x[i]))\r\n",
    "\r\n",
    "def h(x):\r\n",
    "    y = []\r\n",
    "    function = f\r\n",
    "    append = y.append\r\n",
    "    for i in range(len(x)):\r\n",
    "        append(function(x[i]))\r\n",
    "\r\n",
    "def h2(x):\r\n",
    "    y = []\r\n",
    "    function = f\r\n",
    "    for i in range(len(x)):\r\n",
    "        y.append(function(x[i]))\r\n",
    "\r\n",
    "%timeit g([1]*100)\r\n",
    "%timeit h([1]*100)\r\n",
    "%timeit h2([1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, `h` is the most optimized function by putting `f` as a local variable as well as `y.append` therefore it achieves an intersting speed up compared to the non optimized function `g` and semi optimized function `h2` with only 100 elements.\r\n",
    "\r\n",
    "\r\n",
    "In the following code, it's shown that we need to access a global variable as little as possible, as already mentionned: use local variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 µs ± 333 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "3.81 µs ± 609 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x1 = 0\r\n",
    "x2 = 0\r\n",
    "\r\n",
    "def f(x):\r\n",
    "    global x1\r\n",
    "    for elem in x:\r\n",
    "        x1 += elem\r\n",
    "\r\n",
    "\r\n",
    "def g(x):\r\n",
    "    global x2\r\n",
    "    res = 0\r\n",
    "    for elem in x:\r\n",
    "        res += elem\r\n",
    "    x2 += res\r\n",
    "\r\n",
    "\r\n",
    "%timeit f([1]*100)\r\n",
    "%timeit g([1]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to call function as little as possible since it has a high overhead. Therefore, prepare the data before the function and if possible call the function on a X-sized data set rather than call X times the function on each element (the code is from https://wiki.python.org/moin/PythonSpeed/PerformanceTips)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026\n"
     ]
    }
   ],
   "source": [
    "import time\r\n",
    "x = 0\r\n",
    "def doit1(i):\r\n",
    "    global x\r\n",
    "    x = x + i\r\n",
    "\r\n",
    "list = range(100000)\r\n",
    "t = time.time()\r\n",
    "for i in list:\r\n",
    "    doit1(i)\r\n",
    "\r\n",
    "print(\"%.3f\" % (time.time()-t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009\n"
     ]
    }
   ],
   "source": [
    "import time\r\n",
    "x = 0\r\n",
    "def doit2(list):\r\n",
    "    global x\r\n",
    "    for i in list:\r\n",
    "        x = x + i\r\n",
    "\r\n",
    "list = range(100000)\r\n",
    "t = time.time()\r\n",
    "doit2(list)\r\n",
    "print(\"%.3f\" % (time.time()-t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re map functions at runtime\r\n",
    "The code of this section are also taken from the wiki python. The idea is to avoid the if statement that only check if it's called for the first time. We can directly redefined the function after the first call and there are no more `if/else`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.3 ms ± 5.04 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    " class Test:\r\n",
    "    def check(self,a,b,c):\r\n",
    "        if a == 0:\r\n",
    "            self.str = b*100\r\n",
    "        else:\r\n",
    "            self.str = c*100\r\n",
    "\r\n",
    "a = Test()\r\n",
    "def example():\r\n",
    "    for i in range(0,100000):\r\n",
    "        a.check(i,\"b\",\"c\")\r\n",
    "\r\n",
    "%timeit example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.6 ms ± 2.61 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "class Test2:\r\n",
    "    def check(self,a,b,c):\r\n",
    "        self.str = b*100\r\n",
    "        self.check = self.check_post\r\n",
    "    def check_post(self,a,b,c):\r\n",
    "        self.str = c*100\r\n",
    "\r\n",
    "a = Test2()\r\n",
    "def example2():\r\n",
    "    for i in range(0,100000):\r\n",
    "        a.check(i,\"b\",\"c\")\r\n",
    "\r\n",
    "%timeit example2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final tips for this part\r\n",
    "\r\n",
    "* Move computations as much as you can outside of the loops\r\n",
    "* Same for memory allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy code <a name=\"numpy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use vectorization\r\n",
    "\r\n",
    "Indeed vectorization can replace loops and bring the code in the C part to achieve huge speed ups. To do this you need to be comfortable with the indexing notation whose basic elements can be found below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of A[:2,:] = (2, 12)\n",
      "Shape of A[:,1:3] = (10, 2)\n",
      "Shape of A[::2,1] = (5, 12)\n",
      "v[::-1] = [2 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "A = np.random.rand(10,12)\r\n",
    "v = np.array([1,2])\r\n",
    "\r\n",
    "print(\"Shape of A[:2,:] =\", A[:2,:].shape)  # those are the first two rows\r\n",
    "print(\"Shape of A[:,1:3] =\", A[:, 1:3].shape)  # those are the column 1 and 2 so the second and third one in 0 based indexing\r\n",
    "\r\n",
    "print(f\"Shape of A[::2,1] = {A[::2,:].shape}\")  # take one row out of two so those are rows 0,2,4,6,8\r\n",
    "\r\n",
    "print(f\"v[::-1] = {v[::-1]}\")   # reverse the array v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: if you have a function that you want to apply to numpy arrays, think about np.vectorize to vectorize automatically your function (avoid loops). The following example is taken from the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 1 2]\n",
      "[3 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "def myfunc(a, b):   # you just need to create an element function that will be applied elementwise\r\n",
    "    \"Return a-b if a>b, otherwise return a+b\"\r\n",
    "    if a > b:\r\n",
    "        return a - b\r\n",
    "    else:\r\n",
    "        return a + b\r\n",
    "\r\n",
    "vfunc = np.vectorize(myfunc)\r\n",
    "print(vfunc([1, 2, 3, 4], 2))\r\n",
    "print(vfunc([1, 2, 3, 4], [2,1,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local variables\r\n",
    "\r\n",
    "Again, use local variables with arrays to avoid creation of temporary arrays that will slow down the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 µs ± 27.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "492 µs ± 3.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "def f(x):\r\n",
    "    return 2*x**2 + 3*x - 4*x**3\r\n",
    "\r\n",
    "def g(x):\r\n",
    "    gx = 2*x**2\r\n",
    "    gx += 3*x\r\n",
    "    gx -= 4*x**3\r\n",
    "    return gx\r\n",
    "\r\n",
    "%timeit f(np.random.rand(10000))\r\n",
    "%timeit g(np.random.rand(10000))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the speed up can be more important according to the computations inside the function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting\r\n",
    "\r\n",
    "Using broacast allows us to make computations on smaller arrays and then combining them with arrays of the same shape or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the doc:\r\n",
    "> When operating on two arrays, NumPy compares their shapes element-wise. It starts with the trailing (i.e. rightmost) dimensions and works its way left. Two dimensions are compatible when\r\n",
    "\r\n",
    "> 1. they are equal, or\r\n",
    "\r\n",
    "> 2. one of them is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  2. ]\n",
      " [0.5 1. ]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,2,],[1,2]])\r\n",
    "v = np.array([1,2])\r\n",
    "\r\n",
    "print(A/v[:,None])  # divide columnwise such that A[0,:]/v[0] and A[1,:]/v[1]\r\n",
    "print(A/v)          # divide rowwise such that A[:,0]/v[0] and A[:,1]/v[1]\r\n",
    "print(A/v[None,:])  # same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above example, we have not increase the size of `v` to make it work!\r\n",
    "\r\n",
    "\r\n",
    "The example of outer product by broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5 10 15 20]\n",
      " [ 6 12 18 24]\n",
      " [ 7 14 21 28]]\n",
      "[[ 5 10 15 20]\n",
      " [ 6 12 18 24]\n",
      " [ 7 14 21 28]]\n",
      "[[1 2 3 4]]\n",
      "[[5]\n",
      " [6]\n",
      " [7]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4], dtype=np.int16)\r\n",
    "y = np.array([5, 6, 7], dtype=np.int16)\r\n",
    "print(x[np.newaxis,:] * y[:,np.newaxis])   \r\n",
    "print(x[None, :]* y[:,None])\r\n",
    "print(x[np.newaxis,:])\r\n",
    "print(y[:,np.newaxis])\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, `x` will be of shape (1,4) and y (3,1) which will lead to (4,3). it will behaves like if `x` is copied 2 times below it to form a (3,4) matrix and `y` 3 times at its right side to form a (3,4) matrix and then we apply a **element wise** matrix product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In place opeartions\r\n",
    "\r\n",
    "In place operations are much faster and in the following code, we can see that a small change in the code gives us an intersting speed up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.9 ms ± 4.59 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "13.9 ms ± 291 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "a = np.zeros(10**7)\r\n",
    "%timeit global a ; a = 0*a\r\n",
    "%timeit global a ; a *= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid copies when possible\r\n",
    "\r\n",
    "Indeed, copying an array is as costly as making an operation on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.5 ms ± 3.41 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "37.6 ms ± 1.76 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "a = np.zeros(10**7)\r\n",
    "%timeit a.copy()\r\n",
    "%timeit a + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache effects\r\n",
    "\r\n",
    "If you need to go through your array, try to access it in a continuous way and not a random one. In fact, big strides causes caches misses and longer access time.\r\n",
    "\r\n",
    "It can be interesting to choose the ordering: row strorage (default `'C'`) or colmunwise (Fortran ordering `'F'`) according to the computations you have to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.6 ms ± 10.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "146 ms ± 13.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "138 ms ± 4.06 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "91.3 ms ± 2.41 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "(80000, 8)\n",
      "(8, 80000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "c = np.zeros((10**4, 10**4), order='C')\r\n",
    "f = np.zeros((10**4, 10**4), order='F')\r\n",
    "%timeit c.sum(axis=0)\r\n",
    "%timeit f.sum(axis=0)\r\n",
    "%timeit c.sum(axis=1)\r\n",
    "%timeit f.sum(axis=1)\r\n",
    "\r\n",
    "print(c.strides)   # stride[0] is the number of bytes to skip to go to the next row\r\n",
    "print(f.strides)   # stride[1] is the number of bytes to skip to go to the next column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that 1 element is 8 bytes, so this can be intersting to reduce the size of each element if this is possible for example using type uint8 which is 1 byte big so 8x smaller than above. The strides will be smaller and accesses may be faster (this needs to be tried in your particular case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we can force the array (1D, 2D, 3D, ...) to be contiguous in memory which is faster for computations in some cases, you can use numpy.ascontiguousarray to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any time you need to perform operations onto an array by ignoring some elements, think abouts masks which is an efficient way to do computations on a part of an array (avoid for loops).\r\n",
    "\r\n",
    "But **not all NumPy functions respect masks**, for instance np.dot, so check the return types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of a masked array is <class 'numpy.ma.core.MaskedArray'> not a <class 'numpy.ndarray'>\n",
      "Computation like np.mean will ignore the masked elements: np.mean(maskedX) = 2.75\n",
      "But after having done maskedX[1] = 9, x will also be changed! Indeed, x[1] = 9\n",
      "maskedX: [1 -- 3 -- 5]\n",
      "maskedX: [1 9 3 -- 5]\n",
      "We can get the mask with maskedX;mask which gives us [False False False  True False]\n",
      "We can fill the masked values with for example maskedX.filled(-1) that gives us [ 1  9  3 -1  5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "x = np.array([1, 2, 3, -99, 5])\r\n",
    "\r\n",
    "maskedX = np.ma.masked_array(x, mask=[0, 0, 0, 1, 0])\r\n",
    "\r\n",
    "print(f\"The type of a masked array is {type(maskedX)} not a {type(x)}\")\r\n",
    "\r\n",
    "print(f\"Computation like np.mean will ignore the masked elements: np.mean(maskedX) = {np.mean(maskedX)}\")\r\n",
    "\r\n",
    "maskedX[1] = 9\r\n",
    "print(f\"But after having done maskedX[1] = 9, x will also be changed! Indeed, x[1] = {x[1]}\")  # YOU CAN ALSO CHANGE THE MASKED VALUES\r\n",
    "\r\n",
    "maskedX[1] = np.ma.masked  # make the value at index 1 masked\r\n",
    "print(\"maskedX:\", maskedX)\r\n",
    "\r\n",
    "maskedX[1] = 9  # clear the mask by assignment\r\n",
    "print(\"maskedX:\", maskedX)\r\n",
    "\r\n",
    "print(f\"We can get the mask with maskedX;mask which gives us {maskedX.mask}\")\r\n",
    "\r\n",
    "print(f\"We can fill the masked values with for example maskedX.filled(-1) that gives us {maskedX.filled(-1)}\")\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a name=\"ref\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info about strings, list sorting and dictionaries: https://wiki.python.org/moin/PythonSpeed/PerformanceTips\r\n",
    "\r\n",
    "More info about loop otpimization: https://www.python.org/doc/essays/list2str/\r\n",
    "\r\n",
    "More info about numpy arrays in memory: https://hal.inria.fr/inria-00564007/en\r\n",
    "\r\n",
    "More info abut advanced numpy: https://scipy-lectures.org/advanced/advanced_numpy/index.html#advanced-numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further readings: <a name=\"further\"></a>\r\n",
    "\r\n",
    "The `numexpr` is a fast numerical expression evaluator for NumPy.\r\n",
    "\r\n",
    "The `numba` package allows jit compilation and even GPU acceleration with decorators.\r\n",
    "\r\n",
    "`cython` allows to use compiled code and/or make a bridge between python and C codes."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b12d90e444f0f1ab7c6d9d9b47786819133286cf4c5cd905d1f4154a2261e9f9"
  },
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}